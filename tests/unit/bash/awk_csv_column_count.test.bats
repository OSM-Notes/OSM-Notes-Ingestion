#!/usr/bin/env bats

# AWK CSV Column Count Tests
# Tests for validating column count in CSV files generated by AWK scripts
# Author: Andres Gomez (AngocA)
# Version: 2025-11-24

load "${BATS_TEST_DIRNAME}/../../test_helper"

setup() {
 export SCRIPT_BASE_DIRECTORY="$(cd "$(dirname "${BATS_TEST_FILENAME}")/../../.." && pwd)"
 export TMP_DIR="$(mktemp -d)"

 # Create test XML file (API format)
 cat > "${TMP_DIR}/test_api_notes.xml" << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<osm version="0.6" generator="OpenStreetMap server">
  <note lat="40.7128" lon="-74.0060">
    <id>123</id>
    <url>https://www.openstreetmap.org/note/123</url>
    <comment_url>https://www.openstreetmap.org/api/0.6/notes/123/comments</comment_url>
    <close_url>https://www.openstreetmap.org/api/0.6/notes/123/close</close_url>
    <date_created>2023-01-01T00:00:00Z</date_created>
    <status>open</status>
    <comments>
      <comment>
        <date>2023-01-01T00:00:00Z</date>
        <uid>12345</uid>
        <user>testuser</user>
        <action>opened</action>
        <text>Test note</text>
      </comment>
    </comments>
  </note>
  <note lat="40.7129" lon="-74.0061">
    <id>124</id>
    <url>https://www.openstreetmap.org/note/124</url>
    <comment_url>https://www.openstreetmap.org/api/0.6/notes/124/comments</comment_url>
    <close_url>https://www.openstreetmap.org/api/0.6/notes/124/close</close_url>
    <date_created>2023-01-01T01:00:00Z</date_created>
    <date_closed>2023-01-02T10:00:00Z</date_closed>
    <status>closed</status>
    <comments>
      <comment>
        <date>2023-01-01T01:00:00Z</date>
        <uid>12346</uid>
        <user>testuser2</user>
        <action>opened</action>
        <text>Another test note</text>
      </comment>
      <comment>
        <date>2023-01-02T10:00:00Z</date>
        <uid>12346</uid>
        <user>testuser2</user>
        <action>closed</action>
        <text>Closing this note</text>
      </comment>
    </comments>
  </note>
</osm>
EOF

 # Create test XML file (Planet format)
 cat > "${TMP_DIR}/test_planet_notes.xml" << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<osm-notes>
  <note id="125" lat="40.7130" lon="-74.0062" created_at="2023-01-01T02:00:00Z">
    <comment uid="12347" user="testuser3" action="opened" timestamp="2023-01-01T02:00:00Z">Test note 3</comment>
  </note>
</osm-notes>
EOF
}

teardown() {
 rm -rf "${TMP_DIR}"
}

# Helper function to count columns in CSV line
count_columns() {
 local line="$1"
 echo "${line}" | awk -F',' '{print NF}'
}

# Helper function to validate column count
validate_column_count() {
 local csv_file="$1"
 local expected_count="$2"
 local file_type="$3"

 if [[ ! -f "${csv_file}" ]]; then
  echo "ERROR: CSV file not found: ${csv_file}"
  return 1
 fi

 if [[ ! -s "${csv_file}" ]]; then
  echo "WARNING: CSV file is empty: ${csv_file}"
  return 0
 fi

 # Check first non-empty line
 local first_line
 first_line=$(head -1 "${csv_file}" | tr -d '\r\n')

 if [[ -z "${first_line}" ]]; then
  echo "ERROR: First line is empty in ${csv_file}"
  return 1
 fi

 local actual_count
 actual_count=$(count_columns "${first_line}")

 if [[ "${actual_count}" -ne "${expected_count}" ]]; then
  echo "ERROR: ${file_type} CSV has ${actual_count} columns, expected ${expected_count}"
  echo "First line: ${first_line}"
  return 1
 fi

 return 0
}

@test "extract_notes.awk should generate CSV with 8 columns (API format)" {
 local awk_file="${SCRIPT_BASE_DIRECTORY}/awk/extract_notes.awk"
 local output_file="${TMP_DIR}/test_notes.csv"

 [ -f "${awk_file}" ]

 # Process API format XML
 awk -f "${awk_file}" "${TMP_DIR}/test_api_notes.xml" > "${output_file}"

 [ -f "${output_file}" ]
 [ -s "${output_file}" ]

 # Expected columns: note_id,latitude,longitude,created_at,status,closed_at,id_country,part_id
 # Total: 8 columns
 # Standardized order: status before closed_at (matches base table 'notes' structure)
 validate_column_count "${output_file}" 8 "Notes (API format)"

 # Verify column order: first should be note_id (numeric), 5th should be status, 6th should be closed_at
 local first_line
 first_line=$(head -1 "${output_file}" | tr -d '\r\n')

 # Extract fields to verify order
 local note_id
 local status
 local closed_at
 note_id=$(echo "${first_line}" | cut -d',' -f1)
 status=$(echo "${first_line}" | cut -d',' -f5)
 closed_at=$(echo "${first_line}" | cut -d',' -f6)

 # First column should be numeric (note_id)
 [[ "${note_id}" =~ ^[0-9]+$ ]]

 # 5th column should be status (open or close, NOT empty, NOT timestamp)
 [[ -n "${status}" ]] # Must not be empty
 [[ "${status}" =~ ^(open|close)$ ]]
 # Must NOT be a timestamp (if it is, columns are swapped)
 [[ ! "${status}" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}T ]]

 # 6th column should be closed_at (empty or timestamp, NOT status)
 if [[ -n "${closed_at}" ]]; then
  # If not empty, must be a timestamp
  [[ "${closed_at}" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}T ]]
  # Must NOT be status values
  [[ "${closed_at}" != "open" ]]
  [[ "${closed_at}" != "close" ]]
 fi
}

@test "extract_notes.awk should generate CSV with 8 columns (Planet format)" {
 local awk_file="${SCRIPT_BASE_DIRECTORY}/awk/extract_notes.awk"
 local output_file="${TMP_DIR}/test_notes_planet.csv"

 [ -f "${awk_file}" ]

 # Process Planet format XML
 awk -f "${awk_file}" "${TMP_DIR}/test_planet_notes.xml" > "${output_file}"

 [ -f "${output_file}" ]
 [ -s "${output_file}" ]

 # Expected columns: note_id,latitude,longitude,created_at,closed_at,status,id_country,part_id
 # Total: 8 columns
 validate_column_count "${output_file}" 8 "Notes (Planet format)"
}

@test "extract_comments.awk should generate CSV with 7 columns (API format)" {
 local awk_file="${SCRIPT_BASE_DIRECTORY}/awk/extract_comments.awk"
 local output_file="${TMP_DIR}/test_comments.csv"

 [ -f "${awk_file}" ]

 # Process API format XML
 awk -f "${awk_file}" "${TMP_DIR}/test_api_notes.xml" > "${output_file}"

 [ -f "${output_file}" ]
 [ -s "${output_file}" ]

 # Expected columns: note_id,sequence_action,event,created_at,id_user,username,part_id
 # Total: 7 columns
 validate_column_count "${output_file}" 7 "Comments (API format)"

 # Verify column order: 1st should be note_id, 2nd should be sequence_action, 3rd should be event
 local first_line
 first_line=$(head -1 "${output_file}" | tr -d '\r\n')

 local note_id
 local sequence_action
 local event
 note_id=$(echo "${first_line}" | cut -d',' -f1)
 sequence_action=$(echo "${first_line}" | cut -d',' -f2)
 event=$(echo "${first_line}" | cut -d',' -f3)

 # First column should be numeric (note_id)
 [[ "${note_id}" =~ ^[0-9]+$ ]]

 # Second column should be numeric (sequence_action)
 [[ "${sequence_action}" =~ ^[0-9]+$ ]]

 # Third column should be event (opened, closed, etc.)
 [[ "${event}" =~ ^(opened|closed|reopened|commented|hidden)$ ]]
}

@test "extract_comments.awk should generate CSV with 7 columns (Planet format)" {
 local awk_file="${SCRIPT_BASE_DIRECTORY}/awk/extract_comments.awk"
 local output_file="${TMP_DIR}/test_comments_planet.csv"

 [ -f "${awk_file}" ]

 # Process Planet format XML
 awk -f "${awk_file}" "${TMP_DIR}/test_planet_notes.xml" > "${output_file}"

 [ -f "${output_file}" ]
 [ -s "${output_file}" ]

 # Expected columns: note_id,sequence_action,event,created_at,id_user,username,part_id
 # Total: 7 columns
 validate_column_count "${output_file}" 7 "Comments (Planet format)"
}

@test "extract_comment_texts.awk should generate CSV with 4 columns (API format)" {
 local awk_file="${SCRIPT_BASE_DIRECTORY}/awk/extract_comment_texts.awk"
 local output_file="${TMP_DIR}/test_text_comments.csv"

 [ -f "${awk_file}" ]

 # Process API format XML
 awk -f "${awk_file}" "${TMP_DIR}/test_api_notes.xml" > "${output_file}"

 [ -f "${output_file}" ]
 [ -s "${output_file}" ]

 # Expected columns: note_id,sequence_action,"body",part_id
 # Total: 4 columns (body may contain commas, but it's quoted)
 # Note: We need to count columns accounting for quoted fields
 local first_line
 first_line=$(head -1 "${output_file}" | tr -d '\r\n')

 # For quoted CSV, we need a more sophisticated parser
 # Simple check: should have at least 3 commas (4 fields minimum)
 local comma_count
 comma_count=$(echo "${first_line}" | tr -cd ',' | wc -c)

 # Should have exactly 3 commas (4 fields: note_id,sequence_action,body,part_id)
 [ "${comma_count}" -eq 3 ]

 # Verify structure: first field should be note_id (numeric)
 local note_id
 note_id=$(echo "${first_line}" | cut -d',' -f1)
 [[ "${note_id}" =~ ^[0-9]+$ ]]
}

@test "extract_comment_texts.awk should generate CSV with 4 columns (Planet format)" {
 local awk_file="${SCRIPT_BASE_DIRECTORY}/awk/extract_comment_texts.awk"
 local output_file="${TMP_DIR}/test_text_comments_planet.csv"

 [ -f "${awk_file}" ]

 # Process Planet format XML
 awk -f "${awk_file}" "${TMP_DIR}/test_planet_notes.xml" > "${output_file}"

 [ -f "${output_file}" ]
 [ -s "${output_file}" ]

 # Expected columns: note_id,sequence_action,"body",part_id
 # Verify by counting commas (should be 3 for 4 fields)
 local first_line
 first_line=$(head -1 "${output_file}" | tr -d '\r\n')

 local comma_count
 comma_count=$(echo "${first_line}" | tr -cd ',' | wc -c)

 [ "${comma_count}" -eq 3 ]
}


