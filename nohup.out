[0;34m[INFO][0m Running all test modes...

ðŸ”§ Database Tests:
[0;34m[INFO][0m Running tests with real database...
[1;33m[WARNING][0m Unable to switch to notes without password
[1;33m[WARNING][0m Continuing as angoca
[0;34m[INFO][0m Loaded test properties from /home/angoca/github/OSM-Notes/OSM-Notes-Ingestion/tests/properties.sh
[0;32m[SUCCESS][0m Prerequisites validated successfully
[0;34m[INFO][0m Executing database test suites (type: all)
[0;34m[INFO][0m Checking prerequisites...
[0;32m[SUCCESS][0m Prerequisites check completed
[0;34m[INFO][0m Running tests on host system...
[0;34m[INFO][0m Running fast unit tests first...
1..31
ok 1 __parse_timing should extract timing from English format
ok 2 __parse_timing should extract timing from Spanish format
ok 3 __parse_timing should return 0 when no timing found
ok 4 __parse_timing should handle multiple timing lines
ok 5 __check_index_scan should detect Index Scan
ok 6 __check_index_scan should detect Bitmap Index Scan
ok 7 __check_index_scan should not detect index scan when absent
ok 8 __check_seq_scan should detect Sequential Scan
ok 9 __check_seq_scan should not detect seq scan when absent
ok 10 __extract_thresholds should extract threshold from comments
ok 11 __extract_thresholds should handle threshold without comment
ok 12 __check_threshold should pass when actual time is below threshold
ok 13 __check_threshold should fail when actual time exceeds threshold
ok 14 __check_threshold should return 2 when no threshold defined
ok 15 __check_threshold should handle floating point comparison
ok 16 __show_help should display help message
ok 17 Script should find and list analysis scripts
ok 18 Script should handle missing analysis directory gracefully
ok 19 Script should handle empty analysis directory gracefully
ok 20 Script should handle database connection errors
ok 21 Script should handle SQL script execution errors
ok 22 Script should handle timeout scenarios
ok 23 Script should create output directory
ok 24 Script should create summary file
ok 25 Script should generate report file structure
ok 26 Script should accept --db argument
ok 27 Script should accept --verbose argument
ok 28 Script should accept --output argument
ok 29 Script should handle invalid arguments
ok 30 Script should track script execution status
ok 31 Script should categorize results correctly
1..6
ok 1 test verification when API file exists and has content
ok 2 test verification when API file does not exist
ok 3 test verification when API file is empty
ok 4 test verification with valid XML content
ok 5 test direct curl download with waiting
ok 6 test download retry logic
1..6
ok 1 extract_notes.awk should generate CSV with 8 columns (API format)
ok 2 extract_notes.awk should generate CSV with 8 columns (Planet format)
ok 3 extract_comments.awk should generate CSV with 7 columns (API format)
ok 4 extract_comments.awk should generate CSV with 7 columns (Planet format)
ok 5 extract_comment_texts.awk should generate CSV with 4 columns (API format)
ok 6 extract_comment_texts.awk should generate CSV with 4 columns (Planet format)
1..4
ok 1 All CSV files should have consistent column structure across multiple notes
ok 2 CSV consistency should handle notes with different comment counts
ok 3 CSV consistency should handle empty comments gracefully
ok 4 CSV consistency should handle special characters in data
1..4
ok 1 CSV column order should match SQL COPY command expectations (notes)
ok 2 CSV column order should match SQL COPY command expectations (comments)
ok 3 CSV column order should match SQL COPY command expectations (text comments)
ok 4 CSV column order should match SQL COPY command expectations for Planet notes (processPlanetNotes_41)
1..18
ok 1 Enhanced Logger: Basic logging functionality works
ok 2 Enhanced Logger: Log level validation works
ok 3 Enhanced Logger: Log level filtering works correctly
ok 4 Enhanced Logger: File logging works
ok 5 Enhanced Logger: Function timing works
ok 6 Enhanced Logger: All log level aliases work
ok 7 Enhanced Logger: Multiple parameters work
ok 8 Enhanced Logger: Environment variable LOG_LEVEL is respected
ok 9 Enhanced Logger: Invalid log file returns error
ok 10 Enhanced Logger: Log messages include proper format
ok 11 Enhanced Logger: Backwards compatibility maintained
ok 12 Enhanced Logger: Error and Fatal logs go to stderr
ok 13 Enhanced Logger: Integration with OSM Notes scripts
ok 14 Enhanced Logger: Date format is included in all messages
ok 15 Enhanced Logger: Log start and finish include empty lines
ok 16 Enhanced Logger: Original __log function works without level
ok 17 Enhanced Logger: Call stack is shown for TRACE level
ok 18 Enhanced Logger: File descriptor syntax works correctly
1..3
ok 1 binary division function exists
ok 2 traditional division function exists
ok 3 binary division with small file
1..3
ok 1 binary division error handling with invalid input
ok 2 binary division error handling with invalid output directory
ok 3 binary division edge case with empty file
1..6
ok 1 backup files should be detected when they exist
ok 2 __compareIdsWithBackup should return 0 when IDs match
ok 3 __compareIdsWithBackup should return 1 when IDs differ
ok 4 __compareIdsWithBackup should return 1 when backup doesn't exist
ok 5 export scripts should create valid GeoJSON files # skip Database not available
ok 6 backup files should have correct structure
1..1
ok 1 All boundary processing functions should be available
1..24
ok 1 __downloadBoundary_json_geojson_only should download and convert boundary
ok 2 __downloadBoundary_json_geojson_only should fail on download error
ok 3 __downloadBoundary_json_geojson_only should fail on invalid JSON
ok 4 __downloadBoundary_json_geojson_only should fail on conversion error
ok 5 __importBoundary_simplified should import boundary to database
ok 6 __importBoundary_simplified should handle missing GeoJSON file
ok 7 __importBoundary_simplified should handle Austria special case
ok 8 __importBoundary_simplified should fail on ogr2ogr error
ok 9 __downloadMaritime_json_geojson_only should download and convert maritime boundary
ok 10 __downloadMaritime_json_geojson_only should fail on download error
ok 11 __importMaritime_simplified should import maritime boundary to database
ok 12 __importMaritime_simplified should set is_maritime to true
ok 13 __downloadMaritimes_parallel_new should download multiple maritimes in parallel
ok 14 __downloadMaritimes_parallel_new should handle empty file
ok 15 __downloadMaritimes_parallel_new should track failed downloads
ok 16 __importMaritimes_sequential_new should import multiple maritimes sequentially
ok 17 __importMaritimes_sequential_new should handle missing GeoJSON files
ok 18 __importMaritimes_sequential_new should track failed imports
ok 19 __downloadCountries_parallel_new should download multiple countries in parallel
ok 20 __downloadCountries_parallel_new should handle empty file
ok 21 __downloadCountries_parallel_new should track failed downloads
ok 22 __importCountries_sequential_new should import multiple countries sequentially
ok 23 __importCountries_sequential_new should handle missing GeoJSON files
ok 24 __importCountries_sequential_new should track failed imports
1..12
ok 1 __processBoundary_impl should handle TEST_MODE
ok 2 __processCountries_impl should handle basic structure
ok 3 __processCountries_impl should handle empty countries list
ok 4 __processCountries_impl should handle backup comparison
ok 5 __processMaritimes_impl should handle basic structure
ok 6 __processMaritimes_impl should handle empty maritimes list
ok 7 __processMaritimes_impl should handle backup comparison
ok 8 GeoJSON validation should reject empty GeoJSON files
ok 9 GeoJSON validation should reject GeoJSON with no polygon geometries
ok 10 Import table validation should reject empty import table
ok 11 Import table validation should reject import table with no polygons # skip Database not available
ok 12 GeoJSON validation should accept valid GeoJSON with polygon features
1..15
ok 1 __log_download_start should log download start message
ok 2 __log_json_validation_failure should log validation failure
ok 3 __log_download_success should log download success
ok 4 __log_geojson_conversion_start should log conversion start
ok 5 __log_geojson_retry_delay should log retry delay
ok 6 __log_import_start should log import start
ok 7 __log_field_selected_import should log field selected import
ok 8 __log_taiwan_special_handling should log Taiwan handling
ok 9 __log_duplicate_columns_fixed should log duplicate columns fixed
ok 10 __log_duplicate_columns_skip should log duplicate columns skip
ok 11 __log_process_complete should log process complete
ok 12 __log_lock_acquired should log lock acquired
ok 13 __log_lock_failed should log lock failed
ok 14 __log_import_completed should log import completed
ok 15 __log_no_duplicate_columns should log no duplicate columns
1..14
ok 1 __get_countries_table_name should return 'countries' by default
ok 2 __get_countries_table_name should return 'countries_new' when USE_COUNTRIES_NEW=true
ok 3 __get_countries_table_name should return 'countries' when USE_COUNTRIES_NEW=false
ok 4 __get_countries_table_name should return 'countries' when USE_COUNTRIES_NEW is empty
ok 5 __resolve_geojson_file should resolve existing .geojson file
ok 6 __resolve_geojson_file should decompress .geojson.gz file
ok 7 __resolve_geojson_file should handle base path without extension
ok 8 __resolve_geojson_file should return error for non-existent file
ok 9 __validate_capital_location should validate capital location
ok 10 __validate_capital_location should handle missing capital
ok 11 __compareIdsWithBackup should return 0 when IDs match
ok 12 __compareIdsWithBackup should return 1 when IDs differ
ok 13 __compareIdsWithBackup should handle missing Overpass file
ok 14 __compareIdsWithBackup should handle missing backup file
1..7
ok 1 test Taiwan boundary handling - oversized records
ok 2 test Austria boundary handling - topology issues
ok 3 test column duplication detection and handling
ok 4 test ogr2ogr validation with case-sensitive column names
ok 5 test large boundary handling - Taiwan case
ok 6 test Austria topology fix with ST_Buffer
ok 7 test standard boundary processing with ST_makeValid
1..7
ok 1 Centralized validation: processAPINotes.sh should use validation functions
ok 2 Centralized validation: processCheckPlanetNotes.sh should use validation functions
ok 3 Centralized validation: notesCheckVerifier.sh should use validation functions
ok 4 Centralized validation: cleanupAll.sh should use validation functions
ok 5 Centralized validation: processPlanetNotes.sh should use validation functions
ok 6 Centralized validation: all scripts should have consistent validation
ok 7 Centralized validation: validation functions should be available in all scripts
1..9
ok 1 checksum validation should work with matching filename
ok 2 checksum validation should work with non-matching filename (Planet Notes scenario)
ok 3 checksum validation should fail with corrupted file
ok 4 checksum validation should handle single-line MD5 files
ok 5 checksum validation should handle MD5 files with multiple spaces
ok 6 checksum validation should fail with empty MD5 file
ok 7 checksum validation should fail with non-existent MD5 file
ok 8 checksum validation supports different algorithms
ok 9 checksum extraction should handle real Planet Notes MD5 format
1..5
ok 1 trap function __cleanup_on_exit exists in processPlanetNotes
ok 2 trap is set for EXIT in processPlanetNotes
ok 3 __processCountries uses __handle_error_with_cleanup instead of direct exit
ok 4 cleanup function respects CLEAN=true for error exits
ok 5 cleanup function respects CLEAN=false for error exits
1..6
ok 1 error handling should respect CLEAN=false and preserve files
ok 2 error handling should execute cleanup when CLEAN=true
ok 3 error handling should default to CLEAN=true when not set
ok 4 functionsProcess error handling should respect CLEAN=false
ok 5 Planet Notes scenario with CLEAN=false should preserve downloaded files
ok 6 CLEAN flag should be documented in help messages
1..16
ok 1 cleanupAll.sh should be sourceable without errors
ok 2 cleanupAll.sh functions should work without logging errors
ok 3 cleanupAll.sh should work in help mode
ok 4 cleanupAll.sh should have all required functions available
ok 5 cleanupAll.sh logging functions should work correctly
ok 6 cleanupAll.sh database operations should work with test database
ok 7 cleanupAll.sh error handling should work correctly
ok 8 cleanupAll.sh SQL files should be valid
ok 9 cleanupAll.sh should handle no parameters gracefully
ok 10 cleanupAll.sh partition cleanup functions should work correctly
ok 11 cleanupAll.sh database connection functions should work correctly
ok 12 cleanupAll.sh partition detection should work correctly
ok 13 cleanupAll.sh should support partition-only mode
ok 14 cleanupAll.sh should support full cleanup mode
ok 15 cleanupAll.sh should validate command line arguments
ok 16 cleanupAll.sh should handle multiple arguments correctly
1..10
ok 1 cleanupAll script should exist
ok 2 cleanupAll script should be executable
ok 3 cleanupAll script should have correct shebang
ok 4 cleanupAll script should have help function
ok 5 cleanupAll script should have main function
ok 6 cleanupAll script should have cleanup functions
ok 7 cleanupAll script should load validation functions
ok 8 cleanupAll script should have proper error handling
ok 9 cleanupAll script should have logging functions
ok 10 cleanupAll script should have database validation
1..5
ok 1 test __cleanup_validation_temp_files with CLEAN=true
ok 2 test __cleanup_validation_temp_files with CLEAN=false
ok 3 test __cleanup_validation_temp_files with CLEAN unset
ok 4 test __cleanNotesFiles with CLEAN=true
ok 5 test __cleanNotesFiles with CLEAN=false
1..4
ok 1 cleanup order should be correct - Generic Objects before Base Tables
ok 2 DROP TYPE statements should use CASCADE
ok 3 insert_note_comment procedure should be dropped in Generic Objects
ok 4 dependency error scenario should be resolved
1..7
ok 1 cleanupAll should have correct script execution order
ok 2 dropBaseTables script should use CASCADE for dependent types
ok 3 dropGenericObjects script should drop insert_note_comment procedure
ok 4 cleanup scripts should exist and be readable
ok 5 SQL scripts should have valid syntax
ok 6 cleanupAll should handle dependency order correctly
ok 7 dependency issue should be resolved
1..11
ok 1 Required functions are available
ok 2 XML format detection works manually
ok 3 Small API XML file validation works correctly
ok 4 Small Planet XML file validation works correctly
ok 5 Large file detection triggers lite validation
ok 6 Large file coordinate pattern detection works
ok 7 Fallback to minimal validation works when grep fails
ok 8 Timeout handling works for XML operations
ok 9 Error handling works for invalid XML files
ok 10 XML format auto-detection works correctly
ok 11 Large file processing doesn't cause memory issues
1..2
ok 1 extract_comment_texts.awk should handle commas in text (API format)
ok 2 extract_comment_texts.awk should handle commas in text (Planet format)
1..2
ok 1 extract_comment_texts.awk should handle multiline text with quotes and commas (API format)
ok 2 extract_comment_texts.awk should handle complex multiline text (Planet format)
1..1
ok 1 extract_comment_texts.awk should handle multiline text with commas (API format)
1..4
ok 1 extract_comment_texts.awk should handle quotes in text with commas
ok 2 extract_comment_texts.awk should handle single quotes in text API format
ok 3 extract_comment_texts.awk should handle double quotes in text API format
ok 4 extract_comment_texts.awk should handle both single and double quotes in text
1..6
ok 1 CSV validation function should accept valid CSV with commas in text
ok 2 CSV with commas should be parseable by Python CSV parser
ok 3 CSV with commas should maintain correct field count after adding part_id
ok 4 All CSV lines should have consistent field count with commas in text
ok 5 CSV with multiline text should be parseable by Python CSV parser
ok 6 CSV with quotes and commas should maintain text integrity
1..9
ok 1 Enum validation passes for valid comments CSV
ok 2 Enum validation fails for comments CSV with empty event
ok 3 Enum validation fails for comments CSV with invalid event
ok 4 Enum validation passes for valid notes CSV
ok 5 Enum validation fails for notes CSV with invalid status
ok 6 Enum validation handles missing files gracefully
ok 7 Enum validation handles unknown file types
ok 8 Enum validation handles empty files
ok 9 Enum validation counts invalid lines correctly
1..14
ok 1 validate_database_variables with all variables set
ok 2 validate_database_variables with missing DBNAME
ok 3 validate_database_variables with missing DB_USER
ok 4 validate_database_variables with missing TEST variables
ok 5 validate_database_variables with no variables set
ok 6 validate_database_variables with only primary variables
ok 7 validate_database_variables function should be available
ok 8 validate_test_database_variables function should be available
ok 9 validate_all_database_variables function should be available
ok 10 validate_test_database_variables with all test variables set
ok 11 validate_test_database_variables with missing TEST_DBNAME
ok 12 validate_postgres_variables with all variables set
ok 13 validate_postgres_variables with missing POSTGRES_11_CHECK_BASE_TABLES
ok 14 validate_postgres_variables with missing SQL files
1..8
ok 1 processPlanetNotes.sh includes date validation
ok 2 processAPINotes.sh includes date validation
ok 3 date validation functions are available in functionsProcess.sh
ok 4 date validation works with planet XML format
ok 5 date validation works with API XML format
ok 6 date validation fails with invalid dates in XML
ok 7 date validation integration with CSV files
ok 8 date validation fails immediately in strict mode
1..15
ok 1 validate_iso8601_date with valid UTC format
ok 2 validate_iso8601_date with valid timezone offset format
ok 3 validate_iso8601_date with valid API format
ok 4 validate_iso8601_date with empty string
ok 5 validate_iso8601_date with invalid format
ok 6 validate_iso8601_date with invalid year
ok 7 validate_xml_dates with valid XML file
ok 8 validate_xml_dates with custom xpath
ok 9 validate_xml_dates with non-existent file
ok 10 validate_csv_dates with valid CSV file
ok 11 validate_csv_dates with specific column
ok 12 validate_csv_dates with non-existent file
ok 13 validate_csv_dates with CSV without date columns
ok 14 validate_iso8601_date with various valid formats
ok 15 validate_iso8601_date with various invalid formats
1..3
ok 1 test UTC date regex pattern
ok 2 test date component extraction
ok 3 test XML date extraction with UTC format
1..13
ok 1 __get_download_ticket should exist
ok 2 __get_download_ticket should return sequential ticket numbers
ok 3 __wait_for_download_turn should exist
ok 4 __release_download_ticket should exist
ok 5 __wait_for_download_turn should accept ticket when slots available
ok 6 __release_download_ticket should remove lock file
ok 7 __release_download_ticket should advance queue counter
ok 8 queue should handle multiple concurrent tickets
ok 9 __wait_for_download_turn should respect RATE_LIMIT
ok 10 __retry_file_operation should use queue when smart_wait enabled
ok 11 queue should handle cleanup on exit
ok 12 queue directory structure should be created correctly
ok 13 __get_download_ticket should be thread-safe
1..4
ok 1 Edge case: Empty database should be handled gracefully
ok 2 Edge case: Corrupted database should be handled gracefully
ok 3 Edge case: Concurrent access should be handled gracefully
ok 4 Edge case: Data corruption should be handled gracefully
1..2
ok 1 Edge case: Very large XML files should be handled gracefully
ok 2 Edge case: Malformed XML files should be handled gracefully
1..5
ok 1 Edge case: Network connectivity issues should be handled gracefully
ok 2 Edge case: Insufficient disk space should be handled gracefully
ok 3 Edge case: Permission issues should be handled gracefully
ok 4 Edge case: Memory constraints should be handled gracefully
ok 5 Edge case: Invalid configuration should be handled gracefully
1..3
ok 1 Edge case: Missing dependencies should be handled gracefully
ok 2 Edge case: Timeout scenarios should be handled gracefully
ok 3 Edge case: Extreme values should be handled gracefully
1..9
ok 1 check_network_connectivity should succeed with internet
ok 2 handle_error_with_cleanup should execute cleanup commands
ok 3 error handling functions should be available
ok 4 retry_file_operation should succeed with valid operation
